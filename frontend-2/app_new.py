import streamlit as st
import streamlit.components.v1 as components
import json
from datetime import datetime
import requests
import os
import re # Added for graph template handling

# é¢„è®¾æç¤ºè¯åˆ—è¡¨
PRESET_PROMPTS = [
    {
        "name": "é»˜è®¤åŠ©æ‰‹",
        "prompt": "",
        "description": "æ™®é€šå¯¹è¯åŠ©æ‰‹æ¨¡å¼"
    },
    {
        "name": "åˆ›æ„å†™ä½œ",
        "prompt": "ä½ æ˜¯ä¸€ä¸ªå¯Œæœ‰åˆ›æ„çš„å†™ä½œåŠ©æ‰‹ã€‚è¯·å‘æŒ¥æƒ³è±¡åŠ›ï¼Œç”¨ç”ŸåŠ¨æœ‰è¶£çš„è¯­è¨€æ¥åˆ›ä½œå†…å®¹ã€‚ä½ å¯ä»¥å†™æ•…äº‹ã€è¯—æ­Œã€å‰§æœ¬æˆ–è€…ä»»ä½•å½¢å¼çš„åˆ›æ„æ–‡æœ¬ã€‚æ³¨é‡æ–‡é‡‡å’Œåˆ›æ–°ï¼Œè®©æ–‡å­—å……æ»¡ç”Ÿå‘½åŠ›ã€‚",
        "description": "åˆ›æ„æ–‡å­¦åˆ›ä½œå’Œå†™ä½œè¾…åŠ©"
    },
    {
        "name": "ä»£ç ä¸“å®¶",
        "prompt": "ä½ æ˜¯ä¸€ä¸ªç»éªŒä¸°å¯Œçš„ç¼–ç¨‹ä¸“å®¶ã€‚è¯·ç”¨æ¸…æ™°çš„ä»£ç å’Œè¯¦ç»†çš„æ³¨é‡Šæ¥å›ç­”é—®é¢˜ã€‚ä¼˜å…ˆè€ƒè™‘ä»£ç çš„å¯è¯»æ€§å’Œæœ€ä½³å®è·µã€‚",
        "description": "æä¾›ä»£ç ç¤ºä¾‹å’ŒæŠ€æœ¯è§£ç­”"
    },
    {
        "name": "å­¦æœ¯é¡¾é—®",
        "prompt": "ä½ æ˜¯ä¸€ä¸ªä¸¥è°¨çš„å­¦æœ¯é¡¾é—®ã€‚è¯·ç”¨ä¸“ä¸šçš„å­¦æœ¯è¯­è¨€å›ç­”é—®é¢˜ï¼Œå¿…è¦æ—¶æä¾›ç›¸å…³çš„ç ”ç©¶ä¾æ®å’Œå‚è€ƒæ–‡çŒ®ã€‚",
        "description": "å­¦æœ¯é£æ ¼çš„ä¸“ä¸šè§£ç­”"
    },
    {
        "name": "æ•™å­¦åŠ©æ‰‹",
        "prompt": "ä½ æ˜¯ä¸€ä¸ªè€å¿ƒçš„æ•™å­¦åŠ©æ‰‹ã€‚è¯·ç”¨é€šä¿—æ˜“æ‡‚çš„è¯­è¨€è§£é‡Šå¤æ‚çš„æ¦‚å¿µï¼Œé€‚å½“ä½¿ç”¨ç±»æ¯”å’Œä¾‹å­æ¥å¸®åŠ©ç†è§£ã€‚",
        "description": "é€šä¿—æ˜“æ‡‚çš„çŸ¥è¯†è®²è§£"
    }
]

# è®¾ç½®é¡µé¢é…ç½®
st.set_page_config(
    layout="wide",
    initial_sidebar_state="expanded"
)

# æ·»åŠ è‡ªå®šä¹‰CSSæ ·å¼
st.markdown("""
<style>
/* ä¸»å†…å®¹åŒºåŸŸæ ·å¼ */
.main .block-container {
    padding-top: 1rem;
}

/* è‡ªå®šä¹‰æŒ‰é’®æ ·å¼ */
.stButton > button {
    border-radius: 8px;
    border: 1px solid #ddd;
    transition: all 0.3s ease;
}

.stButton > button:hover {
    background-color: #f0f2f5;
    border-color: #ff4b4b;
}

/* å³ä¾§è¾¹æ æ”¶èµ·æŒ‰é’®æ ·å¼ */
div[data-testid="column"]:nth-child(2) .stButton > button[data-testid*="collapse"] {
    width: 30px;
    height: 30px;
    padding: 0;
    display: flex;
    align-items: center;
    justify-content: center;
    background-color: #f8f9fa;
    border: 1px solid #dee2e6;
    border-radius: 6px;
}

div[data-testid="column"]:nth-child(2) .stButton > button[data-testid*="collapse"]:hover {
    background-color: #e9ecef;
    border-color: #adb5bd;
}

/* è¾“å…¥æ¡†æ ·å¼ä¼˜åŒ– */
.stTextInput > div > div > input {
    border-radius: 8px;
    border: 1px solid #ddd;
    padding: 10px 12px;
    font-size: 14px;
}

.stTextInput > div > div > input:focus {
    border-color: #ff4b4b;
    box-shadow: 0 0 0 1px #ff4b4b;
}

/* ç¡®ä¿æ ‡é¢˜å’ŒæŒ‰é’®åœ¨åŒä¸€è¡Œå¯¹é½ */
div[data-testid="column"]:nth-child(2) h3 {
    margin-bottom: 0;
    line-height: 1.2;
}

/* åˆ†å‰²çº¿æ ·å¼ */
hr {
    margin: 1rem 0;
    border: none;
    height: 1px;
    background-color: #e9ecef;
}

/* å“åº”å¼è®¾è®¡ */
@media (max-width: 1200px) {
    .main .block-container {
        padding-right: 1rem !important;
    }
}

@media (max-width: 768px) {
    .main .block-container {
        padding-right: 1rem !important;
    }
}

/* å›ºå®šæŒ‰é’®æ ·å¼ */
.fixed-button {
    position: fixed;
    right: 0;
    top: 50%;
    transform: translateY(-50%);
    background: white;
    border: 1px solid #ddd;
    border-right: none;
    border-radius: 4px 0 0 4px;
    padding: 10px;
    cursor: pointer;
    writing-mode: vertical-lr;
    box-shadow: -2px 0 5px rgba(0,0,0,0.1);
    z-index: 1000;
    transition: all 0.3s ease;
}

.fixed-button:hover {
    background: #f0f2f5;
    box-shadow: -3px 0 8px rgba(0,0,0,0.15);
}

/* ä¾§è¾¹æ æ ·å¼ */
[data-testid="stSidebar"] {
    background-color: #FFFFFF !important;
}

[data-testid="stSidebarNav"] {
    background-color: #FFFFFF !important;
}

[data-testid="stSidebar"]::before {
    display: none;
}

[data-testid="stSidebar"] [data-testid="stMarkdown"] {
    padding-top: 0;
}

[data-testid="stSidebar"] .stButton > button {
    width: 100%;
    border-radius: 5px !important;
    margin-bottom: 0.5rem;
    background: rgba(255, 255, 255, 0.8) !important;
    border: 1px solid rgba(181, 230, 216, 0.3) !important;
    transition: all 0.3s ease !important;
    backdrop-filter: blur(5px);
}

[data-testid="stSidebar"] .stButton > button:hover {
    background: rgba(255, 255, 255, 0.95) !important;
    border-color: #B5E6D8 !important;
    transform: translateY(-1px) !important;
    box-shadow: 0 2px 5px rgba(0,0,0,0.1) !important;
}

[data-testid="stSidebar"] hr {
    margin: 1rem 0 !important;
    border: none !important;
    height: 1px !important;
    background-color: rgba(224, 224, 224, 0.3) !important;
}

[data-testid="stSidebar"] h1 {
    color: #2C3E50;
    font-size: 1.5rem;
    margin-bottom: 1rem;
    text-shadow: 1px 1px 2px rgba(255, 255, 255, 0.8);
}

[data-testid="stSidebar"] h2 {
    color: #34495E;
    font-size: 1.2rem;
    margin: 1rem 0;
    text-shadow: 1px 1px 2px rgba(255, 255, 255, 0.8);
}

/* Logoæ ·å¼ */
[data-testid="stImage"] {
    position: relative !important;
    left: 0 !important;
    top: 0 !important;
    margin: 0 !important;
    padding: 0 !important;
    background-color: #FFFFFF !important;
    width: 100% !important;
}

[data-testid="stImage"] img {
    margin: 0.5rem !important;
}

/* çŸ¥è¯†å›¾è°±æŒ‰é’®æ ·å¼ */
.knowledge-graph-btn {
    margin-top: 1rem;
    margin-bottom: 1rem;
    text-align: center;
}

/* çŸ¥è¯†å›¾è°±å®¹å™¨æ ·å¼ */
.knowledge-graph-container {
    width: 100%;
    height: 600px;
    border: 1px solid #e0e0e0;
    border-radius: 8px;
    margin-top: 1rem;
    overflow: hidden;
}

/* åˆ†æ æ ·å¼ */
.chat-column {
    padding-right: 10px;
}

.graph-column {
    border-left: 1px solid #e0e0e0;
    padding-left: 10px;
}

</style>
""", unsafe_allow_html=True)

st.title("Gridseek")

# åˆå§‹åŒ–session state
if 'messages' not in st.session_state:
    st.session_state.messages = []
if 'sessions' not in st.session_state:
    st.session_state.sessions = {}  # ä½¿ç”¨å­—å…¸è€Œä¸æ˜¯åˆ—è¡¨
if 'current_session' not in st.session_state:
    st.session_state.current_session = None
if 'show_graph' not in st.session_state:
    st.session_state.show_graph = False
if 'triplets' not in st.session_state:
    st.session_state.triplets = []
if 'available_models' not in st.session_state:
    st.session_state.available_models = []
if 'current_model' not in st.session_state:
    st.session_state.current_model = "gpt-4o-mini"  # é»˜è®¤æ¨¡å‹
if 'temperature' not in st.session_state:
    st.session_state.temperature = 0.7
if 'system_prompt' not in st.session_state:
    st.session_state.system_prompt = ""  # é»˜è®¤ç©ºæç¤ºè¯
if 'prompt_mode' not in st.session_state:
    st.session_state.prompt_mode = "é¢„è®¾"  # é»˜è®¤ä½¿ç”¨é¢„è®¾æç¤ºè¯
if 'selected_preset_prompt' not in st.session_state:
    st.session_state.selected_preset_prompt = "é»˜è®¤åŠ©æ‰‹"  # é»˜è®¤ä½¿ç”¨é»˜è®¤åŠ©æ‰‹

def toggle_knowledge_graph():
    """åˆ‡æ¢çŸ¥è¯†å›¾è°±æ˜¾ç¤ºçŠ¶æ€"""
    st.session_state.show_graph = not st.session_state.show_graph

def load_available_models():
    """ä»åç«¯åŠ è½½å¯ç”¨æ¨¡å‹åˆ—è¡¨"""
    try:
        response = requests.get('http://localhost:8000/api/qa/models', timeout=10)
        response.raise_for_status()
        models = response.json()
        st.session_state.available_models = models
        return True
    except requests.RequestException as e:
        st.error(f"åŠ è½½æ¨¡å‹åˆ—è¡¨å¤±è´¥: {e}")
        # è®¾ç½®é»˜è®¤æ¨¡å‹åˆ—è¡¨ä½œä¸ºå¤‡é€‰
        st.session_state.available_models = [
            {"model_name": "gpt-4o-mini", "description": "OpenAI GPT-4o-mini, æ€§èƒ½ä¼˜ç§€ï¼Œæˆæœ¬è¾ƒä½ã€‚"},
            {"model_name": "deepseek-chat", "description": "DeepSeek Chat, ä¸­æ–‡è¡¨ç°ä¼˜ç§€çš„å¼€æºæ¨¡å‹ã€‚"}
        ]
        return False
    except Exception as e:
        st.error(f"å¤„ç†æ¨¡å‹åˆ—è¡¨æ—¶å‡ºé”™: {e}")
        return False

def change_model(new_model):
    """åˆ‡æ¢å½“å‰ä½¿ç”¨çš„æ¨¡å‹"""
    st.session_state.current_model = new_model
    st.toast(f"å·²åˆ‡æ¢åˆ°æ¨¡å‹: {new_model}", icon="ğŸ¤–")

def change_temperature(new_temperature):
    """æ›´æ”¹æ¨¡å‹æ¸©åº¦å‚æ•°"""
    st.session_state.temperature = new_temperature

def check_model_connectivity():
    """æ£€æŸ¥æ¨¡å‹è¿æ¥çŠ¶æ€"""
    try:
        response = requests.get('http://localhost:8000/api/qa/models', timeout=5)
        response.raise_for_status()
        return True, "åç«¯è¿æ¥æ­£å¸¸"
    except requests.RequestException as e:
        return False, f"åç«¯è¿æ¥å¤±è´¥: {e}"

def save_chat_history():
    """ä¿å­˜èŠå¤©å†å²"""
    try:
        chat_history = {}
        for session_id, messages in st.session_state.sessions.items():
            chat_history[session_id] = messages
            
        with open('chat_history.json', 'w', encoding='utf-8') as f:
            json.dump(chat_history, f, ensure_ascii=False, indent=2)
    except Exception as e:
        st.error(f"ä¿å­˜èŠå¤©å†å²å¤±è´¥ï¼š{str(e)}")

def load_chat_history():
    """åŠ è½½èŠå¤©å†å²"""
    try:
        with open('chat_history.json', 'r', encoding='utf-8') as f:
            chat_history = json.load(f)
            st.session_state.sessions = chat_history
            
            # å¦‚æœæ˜¯å½“å‰ä¼šè¯ï¼Œæ›´æ–°messages
            if st.session_state.current_session in chat_history:
                st.session_state.messages = chat_history[st.session_state.current_session].copy()
    except FileNotFoundError:
        st.session_state.sessions = {}
    except Exception as e:
        st.error(f"åŠ è½½èŠå¤©å†å²å¤±è´¥ï¼š{str(e)}")
        st.session_state.sessions = {}

def create_new_session():
    """åˆ›å»ºæ–°ä¼šè¯"""
    # ç”Ÿæˆæ–°çš„ä¼šè¯IDï¼Œç¡®ä¿å”¯ä¸€æ€§
    base_id = len(st.session_state.sessions) + 1
    session_id = f"ä¼šè¯{base_id}"
    
    # å¦‚æœä¼šè¯IDå·²å­˜åœ¨ï¼Œå¢åŠ æ•°å­—ç›´åˆ°æ‰¾åˆ°å”¯ä¸€çš„ID
    while session_id in st.session_state.sessions:
        base_id += 1
        session_id = f"ä¼šè¯{base_id}"
    
    # åˆ›å»ºæ–°ä¼šè¯
    st.session_state.sessions[session_id] = []
    st.session_state.current_session = session_id
    st.session_state.messages = []
    save_chat_history()

def switch_session(session_id):
    """åˆ‡æ¢ä¼šè¯"""
    st.session_state.current_session = session_id
    st.session_state.messages = st.session_state.sessions[session_id]

def clear_session():
    """æ¸…ç©ºå½“å‰ä¼šè¯"""
    if st.session_state.current_session:
        st.session_state.messages = []
        st.session_state.sessions[st.session_state.current_session] = []
        save_chat_history()

def delete_session(session_id):
    """åˆ é™¤å½“å‰ä¼šè¯"""
    if st.session_state.current_session == session_id:
        st.session_state.current_session = None
        st.session_state.messages = []
    st.session_state.sessions.pop(session_id, None)
    save_chat_history()

def extract_and_store_triplets(text: str):
    """ä»æ–‡æœ¬ä¸­æå–ä¸‰å…ƒç»„å¹¶å­˜å‚¨åˆ°session_state"""
    try:
        # æ‰“å°è°ƒè¯•ä¿¡æ¯
        st.write(f"æ­£åœ¨ä»æ–‡æœ¬ä¸­æå–ä¸‰å…ƒç»„ï¼Œæ–‡æœ¬é•¿åº¦: {len(text)}")
        
        # ç¡®ä¿textä¸ä¸ºç©º
        if not text or len(text.strip()) < 10:
            st.warning("æ–‡æœ¬å†…å®¹è¿‡çŸ­ï¼Œæ— æ³•æå–æœ‰æ•ˆçš„ä¸‰å…ƒç»„")
            return False
            
        # æ˜¾ç¤ºæ­£åœ¨å¤„ç†çš„çŠ¶æ€
        with st.spinner("æ­£åœ¨æå–çŸ¥è¯†ä¸‰å…ƒç»„..."):
            # ç¡®ä¿ä½¿ç”¨æ­£ç¡®çš„APIç«¯ç‚¹
            api_url = 'http://localhost:8000/api/kg/extract'
            st.write(f"è°ƒç”¨API: {api_url}")
            
            # å‡†å¤‡è¯·æ±‚æ•°æ®å¹¶æ‰“å°
            request_data = {'text': text}
            st.write(f"è¯·æ±‚æ•°æ®ç¤ºä¾‹: {{'text': '{text[:50]}...'}}")
            
            # å‘é€è¯·æ±‚
            response = requests.post(
                api_url,
                json=request_data,
                timeout=30  # å¢åŠ è¶…æ—¶æ—¶é—´
            )
            
            # æ£€æŸ¥å“åº”çŠ¶æ€
            response.raise_for_status()
            st.write(f"APIå“åº”çŠ¶æ€ç : {response.status_code}")
            
            # è§£æå“åº”æ•°æ®
            data = response.json()
            st.write(f"APIå“åº”æ•°æ®: {data}")
            
            # æå–ä¸‰å…ƒç»„
            new_triplets = data.get("triples", [])
            st.write(f"æå–åˆ°çš„ä¸‰å…ƒç»„æ•°é‡: {len(new_triplets)}")
            
            if new_triplets:
                # è·å–ç°æœ‰ä¸‰å…ƒç»„
                existing_triplets = st.session_state.get('triplets', [])
                st.write(f"ç°æœ‰ä¸‰å…ƒç»„æ•°é‡: {len(existing_triplets)}")
                
                # å°†æ–°çš„ä¸‰å…ƒç»„æ·»åŠ è¿›å»ï¼ŒåŒæ—¶å»é‡
                added_count = 0
                for triplet in new_triplets:
                    if triplet not in existing_triplets:
                        existing_triplets.append(triplet)
                        added_count += 1
                
                st.write(f"æ–°å¢ä¸‰å…ƒç»„æ•°é‡: {added_count}")
                st.session_state.triplets = existing_triplets
                st.toast(f"æå–åˆ° {len(new_triplets)} ä¸ªçŸ¥è¯†ä¸‰å…ƒç»„ï¼Œæ–°å¢ {added_count} ä¸ªï¼", icon="âœ¨")
                return True  # è¡¨ç¤ºæœ‰æ–°çš„ä¸‰å…ƒç»„è¢«æ·»åŠ 
            else:
                st.warning("æœªèƒ½ä»æ–‡æœ¬ä¸­æå–åˆ°ä»»ä½•ä¸‰å…ƒç»„")
                return False  # è¡¨ç¤ºæ²¡æœ‰æ–°çš„ä¸‰å…ƒç»„

    except requests.RequestException as e:
        st.error(f"æå–çŸ¥è¯†ä¸‰å…ƒç»„å¤±è´¥ï¼š{e}")
        st.write(f"è¯·æ±‚å¼‚å¸¸è¯¦æƒ…: {str(e)}")
        return False
    except Exception as e:
        st.error(f"å¤„ç†ä¸‰å…ƒç»„æ—¶å‡ºé”™: {e}")
        st.write(f"å¼‚å¸¸è¯¦æƒ…: {str(e)}")
        import traceback
        st.write(f"å¼‚å¸¸å †æ ˆ: {traceback.format_exc()}")
        return False
    finally:
        # ç§»é™¤è°ƒè¯•ä¿¡æ¯ï¼ˆç”Ÿäº§ç¯å¢ƒä¸­åº”è¯¥æ³¨é‡Šæ‰è¿™äº›è°ƒè¯•è¾“å‡ºï¼‰
        # è¿™é‡Œæˆ‘ä»¬æš‚æ—¶ä¿ç•™ï¼Œä¾¿äºæ’æŸ¥é—®é¢˜
        pass

# æ·»åŠ ä¸€ä¸ªæµ‹è¯•å‡½æ•°ï¼Œç”¨äºç›´æ¥æµ‹è¯•ä¸‰å…ƒç»„æå–åŠŸèƒ½
def test_triplet_extraction():
    """æµ‹è¯•ä¸‰å…ƒç»„æå–åŠŸèƒ½"""
    st.subheader("ä¸‰å…ƒç»„æå–æµ‹è¯•")
    test_text = st.text_area(
        "è¾“å…¥æµ‹è¯•æ–‡æœ¬", 
        value="äººå·¥æ™ºèƒ½æ˜¯è®¡ç®—æœºç§‘å­¦çš„ä¸€ä¸ªåˆ†æ”¯ï¼Œå®ƒè‡´åŠ›äºåˆ›é€ èƒ½å¤Ÿæ¨¡æ‹Ÿäººç±»æ™ºèƒ½çš„æœºå™¨ã€‚",
        height=150
    )
    
    if st.button("æµ‹è¯•æå–ä¸‰å…ƒç»„"):
        if test_text:
            extract_and_store_triplets(test_text)
        else:
            st.error("è¯·è¾“å…¥æµ‹è¯•æ–‡æœ¬")

def test_model_switching():
    """æµ‹è¯•æ¨¡å‹åˆ‡æ¢åŠŸèƒ½"""
    st.subheader("ğŸ¤– æ¨¡å‹åˆ‡æ¢æµ‹è¯•")
    
    # æ˜¾ç¤ºå½“å‰æ¨¡å‹ä¿¡æ¯
    st.info(f"å½“å‰æ¨¡å‹: {st.session_state.current_model}")
    st.info(f"å½“å‰æ¸©åº¦: {st.session_state.temperature}")
    
    # æµ‹è¯•é—®é¢˜
    test_question = st.text_input(
        "æµ‹è¯•é—®é¢˜:",
        value="è¯·ç®€å•ä»‹ç»ä¸€ä¸‹ä½ è‡ªå·±",
        help="è¾“å…¥ä¸€ä¸ªæµ‹è¯•é—®é¢˜æ¥éªŒè¯æ¨¡å‹åˆ‡æ¢æ˜¯å¦ç”Ÿæ•ˆ"
    )
    
    if st.button("æµ‹è¯•å½“å‰æ¨¡å‹", key="test_current_model"):
        if test_question:
            with st.spinner(f"æ­£åœ¨ä½¿ç”¨ {st.session_state.current_model} å›ç­”..."):
                try:
                    # ç›´æ¥è°ƒç”¨åç«¯APIæµ‹è¯•
                    response = requests.post(
                        'http://localhost:8000/api/qa',
                        json={
                            'question': test_question,
                            'model_name': st.session_state.current_model,
                            'temperature': st.session_state.temperature,
                            'system_prompt': st.session_state.system_prompt
                        },
                        timeout=30
                    )
                    response.raise_for_status()
                    data = response.json()
                    
                    if data.get('status') == 'success':
                        st.success(f"âœ… æ¨¡å‹ {data.get('model_name')} å“åº”æˆåŠŸ!")
                        st.markdown(f"**å›ç­”:** {data.get('response_message')}")
                    else:
                        st.error(f"âŒ æ¨¡å‹å“åº”å¤±è´¥: {data.get('error')}")
                        
                except requests.RequestException as e:
                    st.error(f"âŒ è¯·æ±‚å¤±è´¥: {e}")
                except Exception as e:
                    st.error(f"âŒ å¤„ç†å“åº”æ—¶å‡ºé”™: {e}")
        else:
            st.warning("è¯·è¾“å…¥æµ‹è¯•é—®é¢˜")
    
    # å¿«é€Ÿåˆ‡æ¢æµ‹è¯•
    st.subheader("å¿«é€Ÿæ¨¡å‹åˆ‡æ¢æµ‹è¯•")
    if st.session_state.available_models:
        cols = st.columns(len(st.session_state.available_models))
        for i, model in enumerate(st.session_state.available_models):
            with cols[i]:
                model_name = model["model_name"]
                is_current = model_name == st.session_state.current_model
                if st.button(
                    f"{'âœ…' if is_current else 'ğŸ”„'} {model_name}",
                    key=f"quick_switch_{model_name}",
                    help=f"åˆ‡æ¢åˆ° {model_name}",
                    type="primary" if is_current else "secondary"
                ):
                    if not is_current:
                        change_model(model_name)
                        st.rerun()

def generate_dynamic_graph_html(triplets: list) -> str:
    """æ ¹æ®ä¸‰å…ƒç»„åŠ¨æ€ç”Ÿæˆgraph.htmlå†…å®¹"""
    if not triplets:
        return "<h3>å½“å‰è¿˜æ²¡æœ‰å¯æ˜¾ç¤ºçš„çŸ¥è¯†ä¸‰å…ƒç»„ã€‚</h3>"
        
    # ä¸ºèŠ‚ç‚¹å’Œè¾¹ç”Ÿæˆéšæœºé¢œè‰²
    import random
    def get_random_color():
        # ç”ŸæˆæŸ”å’Œçš„é¢œè‰²
        r = random.randint(100, 200)
        g = random.randint(100, 200)
        b = random.randint(100, 200)
        return f"#{r:02x}{g:02x}{b:02x}"
    
    # ä¸ºå®ä½“ç±»å‹åˆ†é…å›ºå®šé¢œè‰²
    entity_colors = {}
    
    nodes_set = set()
    nodes_js = []
    edges_js = []
    
    # é¦–å…ˆæ”¶é›†æ‰€æœ‰å”¯ä¸€çš„å®ä½“
    for triplet in triplets:
        h, r, t = triplet.get('h'), triplet.get('r'), triplet.get('t')
        if not all([h, r, t]):
            continue
            
        nodes_set.add(h)
        nodes_set.add(t)
    
    # ä¸ºæ¯ä¸ªå®ä½“åˆ†é…é¢œè‰²
    for entity in nodes_set:
        if entity not in entity_colors:
            entity_colors[entity] = get_random_color()
    
    # ç”ŸæˆèŠ‚ç‚¹æ•°æ®
    for i, entity in enumerate(nodes_set):
        color = entity_colors.get(entity, "#7DCEA0")  # é»˜è®¤é¢œè‰²
        border_color = color  # è¾¹æ¡†é¢œè‰²ç¨æ·±
        
        # ä½¿ç”¨å®ä½“åä½œä¸ºIDï¼Œé¿å…é‡å¤
        node_id = f'"{entity}"'  # ç¡®ä¿IDæ˜¯å­—ç¬¦ä¸²
        nodes_js.append(f'{{id: {node_id}, label: "{entity}", title: "{entity}", ' +
                      f'color: {{ background: "{color}", border: "{border_color}" }}}}')
    
    # ç”Ÿæˆè¾¹æ•°æ®
    for i, triplet in enumerate(triplets):
        h, r, t = triplet.get('h'), triplet.get('r'), triplet.get('t')
        if not all([h, r, t]):
            continue
            
        # ä½¿ç”¨å®ä½“åä½œä¸ºID
        from_id = f'"{h}"'
        to_id = f'"{t}"'
        
        edges_js.append(f'{{from: {from_id}, to: {to_id}, arrows: "to", label: "{r}"}}')
    
    nodes_str = ",\n        ".join(nodes_js)
    edges_str = ",\n        ".join(edges_js)
    
    # è¯»å–HTMLæ¨¡æ¿æ–‡ä»¶
    try:
        # å°è¯•å¤šç§å¯èƒ½çš„è·¯å¾„
        possible_paths = [
            "graph_template.html",  # å½“å‰ç›®å½•
            "./graph_template.html",  # æ˜¾å¼å½“å‰ç›®å½•
            "frontend-2/graph_template.html",  # ç›¸å¯¹äºé¡¹ç›®æ ¹ç›®å½•
            "./frontend-2/graph_template.html",  # æ˜¾å¼ç›¸å¯¹äºé¡¹ç›®æ ¹ç›®å½•
            "v3_st/frontend-2/graph_template.html",  # å®Œæ•´ç›¸å¯¹è·¯å¾„
            "./v3_st/frontend-2/graph_template.html",  # æ˜¾å¼å®Œæ•´ç›¸å¯¹è·¯å¾„
        ]
        
        template_content = None
        used_path = None
        
        for path in possible_paths:
            try:
                with open(path, 'r', encoding='utf-8') as f:
                    template_content = f.read()
                    used_path = path
                    break
            except FileNotFoundError:
                continue
        
        if not template_content:
            # å¦‚æœæ‰€æœ‰è·¯å¾„éƒ½å¤±è´¥ï¼Œå°è¯•ä½¿ç”¨graph.htmlä½œä¸ºå¤‡ç”¨
            backup_paths = [
                "graph.html",
                "./graph.html",
                "frontend-2/graph.html",
                "./frontend-2/graph.html",
                "v3_st/frontend-2/graph.html",
                "./v3_st/frontend-2/graph.html",
            ]
            
            for path in backup_paths:
                try:
                    with open(path, 'r', encoding='utf-8') as f:
                        template_content = f.read()
                        used_path = path
                        st.warning(f"ä½¿ç”¨å¤‡ç”¨æ¨¡æ¿æ–‡ä»¶: {path}")
                        break
                except FileNotFoundError:
                    continue
        
        if not template_content:
            raise FileNotFoundError("æ— æ³•æ‰¾åˆ°ä»»ä½•å¯ç”¨çš„å›¾è°±æ¨¡æ¿æ–‡ä»¶")
            
        st.success(f"æˆåŠŸåŠ è½½æ¨¡æ¿æ–‡ä»¶: {used_path}")
            
        # æ›¿æ¢å ä½ç¬¦
        # é¦–å…ˆæ£€æŸ¥æ¨¡æ¿ä¸­æ˜¯å¦åŒ…å«å ä½ç¬¦
        if "{{NODES_PLACEHOLDER}}" in template_content and "{{EDGES_PLACEHOLDER}}" in template_content:
            html_content = template_content.replace("{{NODES_PLACEHOLDER}}", nodes_str)
            html_content = html_content.replace("{{EDGES_PLACEHOLDER}}", edges_str)
        else:
            # å¦‚æœæ²¡æœ‰æ‰¾åˆ°å ä½ç¬¦ï¼Œå°è¯•åœ¨é€‚å½“ä½ç½®æ’å…¥æ•°æ®
            # è¿™æ˜¯ä¸€ä¸ªå¤‡ç”¨æ–¹æ¡ˆï¼Œç”¨äºå¤„ç†æ²¡æœ‰å ä½ç¬¦çš„æ¨¡æ¿
            html_content = template_content
            
            # å¯»æ‰¾nodeså®šä¹‰çš„ä½ç½®
            nodes_pattern = r"var\s+nodes\s*=\s*new\s+vis\.DataSet\(\s*\[\s*"
            if re.search(nodes_pattern, html_content):
                html_content = re.sub(
                    nodes_pattern + r".*?\]\s*\);",
                    f"var nodes = new vis.DataSet([{nodes_str}]);",
                    html_content,
                    flags=re.DOTALL
                )
                
            # å¯»æ‰¾edgeså®šä¹‰çš„ä½ç½®
            edges_pattern = r"var\s+edges\s*=\s*new\s+vis\.DataSet\(\s*\[\s*"
            if re.search(edges_pattern, html_content):
                html_content = re.sub(
                    edges_pattern + r".*?\]\s*\);",
                    f"var edges = new vis.DataSet([{edges_str}]);",
                    html_content,
                    flags=re.DOTALL
                )
        
        return html_content
    except FileNotFoundError as e:
        st.error(f"æ‰¾ä¸åˆ°æ¨¡æ¿æ–‡ä»¶: {str(e)}")
        return f"<h3>é”™è¯¯ï¼šæ‰¾ä¸åˆ°å›¾è°±æ¨¡æ¿æ–‡ä»¶ã€‚è¯·ç¡®ä¿å›¾è°±æ¨¡æ¿æ–‡ä»¶å­˜åœ¨ã€‚</h3><p>å°è¯•è¿‡çš„è·¯å¾„: {', '.join(possible_paths)}</p>"
    except Exception as e:
        st.error(f"ç”Ÿæˆå›¾è°±æ—¶å‡ºé”™: {e}")
        import traceback
        st.write(f"å¼‚å¸¸å †æ ˆ: {traceback.format_exc()}")
        return f"<h3>ç”Ÿæˆå›¾è°±æ—¶å‡ºé”™: {e}</h3>"

def render_knowledge_graph():
    """æ¸²æŸ“çŸ¥è¯†å›¾è°±"""
    triplets = st.session_state.get('triplets', [])
    if not triplets:
        st.info("å½“å‰è¿˜æ²¡æœ‰å¯æ˜¾ç¤ºçš„çŸ¥è¯†ä¸‰å…ƒç»„ã€‚")
        return
    
    st.subheader("çŸ¥è¯†å›¾è°±å¯è§†åŒ–")    
    dynamic_html = generate_dynamic_graph_html(triplets)
    components.html(dynamic_html, height=600, scrolling=True)

# ä¸»å‡½æ•°
def main():
    # åŠ è½½èŠå¤©å†å²
    load_chat_history()
    
    # åŠ è½½å¯ç”¨æ¨¡å‹åˆ—è¡¨ï¼ˆå¦‚æœè¿˜æ²¡æœ‰åŠ è½½ï¼‰
    if not st.session_state.available_models:
        load_available_models()
    
    # ä¾§è¾¹æ ï¼šä¼šè¯ç®¡ç†
    with st.sidebar:
        st.image("logo/logo.png", use_container_width=True)
        st.title("å¯¹è¯ç®¡ç†")
        
        if st.button("æ–°å»ºä¼šè¯", help="åˆ›å»ºä¸€ä¸ªæ–°çš„å¯¹è¯"):
            create_new_session()
            st.rerun()
        st.divider()
        
        st.subheader("å†å²ä¼šè¯")
        sorted_sessions = sorted(st.session_state.sessions.items(), 
                               key=lambda x: int(x[0].replace("ä¼šè¯", "")))
        
        for session_id, _ in sorted_sessions:
            col1, col2 = st.columns([4, 1])
            with col1:
                is_current = session_id == st.session_state.current_session
                button_text = f"ğŸ“ {session_id}" + (" âœ“" if is_current else "")
                if st.button(button_text, key=f"session_{session_id}", 
                           help="ç‚¹å‡»åˆ‡æ¢åˆ°æ­¤å¯¹è¯",
                           type="primary" if is_current else "secondary"):
                    switch_session(session_id)
                    st.rerun()
            with col2:
                if st.button("ğŸ—‘", key=f"delete_{session_id}", help="åˆ é™¤æ­¤å¯¹è¯"):
                    delete_session(session_id)
                    st.rerun()
        
        st.divider()
        
        if st.button("æ¸…ç©ºå½“å‰ä¼šè¯", 
                    help="æ¸…ç©ºå½“å‰å¯¹è¯çš„æ‰€æœ‰æ¶ˆæ¯",
                    disabled=not st.session_state.current_session):
            clear_session()
            st.rerun()
        st.divider()
        
        # æ¨¡å‹è®¾ç½®éƒ¨åˆ†
        st.subheader("ğŸ¤– æ¨¡å‹è®¾ç½®")
        
        # æ˜¾ç¤ºè¿æ¥çŠ¶æ€
        is_connected, status_msg = check_model_connectivity()
        if is_connected:
            st.success(f"âœ… {status_msg}")
        else:
            st.error(f"âŒ {status_msg}")
        
        # åŠ è½½å¯ç”¨æ¨¡å‹ï¼ˆå¦‚æœè¿˜æ²¡æœ‰åŠ è½½ï¼‰
        if not st.session_state.available_models:
            load_available_models()
        
        # æ¨¡å‹é€‰æ‹©å™¨
        if st.session_state.available_models:
            model_options = [model["model_name"] for model in st.session_state.available_models]
            model_descriptions = {model["model_name"]: model["description"] 
                                for model in st.session_state.available_models}
            
            # ç¡®ä¿å½“å‰æ¨¡å‹åœ¨å¯ç”¨æ¨¡å‹åˆ—è¡¨ä¸­
            if st.session_state.current_model not in model_options:
                st.session_state.current_model = model_options[0] if model_options else "gpt-4o-mini"
            
            selected_model = st.selectbox(
                "é€‰æ‹© AI æ¨¡å‹:",
                options=model_options,
                index=model_options.index(st.session_state.current_model) if st.session_state.current_model in model_options else 0,
                format_func=lambda x: f"{x} ({model_descriptions.get(x, '').split(',')[0]})",
                help="é€‰æ‹©ç”¨äºå¯¹è¯çš„ AI æ¨¡å‹",
                key="model_selector"
            )
            
            # å½“æ¨¡å‹é€‰æ‹©å‘ç”Ÿå˜åŒ–æ—¶
            if selected_model != st.session_state.current_model:
                change_model(selected_model)
                st.rerun()
            
            # æ˜¾ç¤ºå½“å‰æ¨¡å‹çš„è¯¦ç»†æè¿°
            if selected_model in model_descriptions:
                st.caption(f"ğŸ“ {model_descriptions[selected_model]}")
            
            # æ¸©åº¦è°ƒèŠ‚å™¨
            new_temperature = st.slider(
                "åˆ›é€ æ€§ (Temperature):",
                min_value=0.0,
                max_value=1.0,
                value=st.session_state.temperature,
                step=0.1,
                help="è¾ƒä½çš„å€¼è®©å›ç­”æ›´ç¡®å®šï¼Œè¾ƒé«˜çš„å€¼è®©å›ç­”æ›´å…·åˆ›é€ æ€§",
                key="temperature_slider"
            )
            
            # å½“æ¸©åº¦å‘ç”Ÿå˜åŒ–æ—¶
            if new_temperature != st.session_state.temperature:
                change_temperature(new_temperature)
            
            # åˆ·æ–°æ¨¡å‹åˆ—è¡¨æŒ‰é’®
            if st.button("ğŸ”„ åˆ·æ–°æ¨¡å‹åˆ—è¡¨", help="é‡æ–°ä»åç«¯è·å–å¯ç”¨æ¨¡å‹"):
                with st.spinner("æ­£åœ¨åŠ è½½æ¨¡å‹åˆ—è¡¨..."):
                    load_available_models()
                st.rerun()
        else:
            st.warning("æ— æ³•åŠ è½½æ¨¡å‹åˆ—è¡¨ï¼Œè¯·æ£€æŸ¥åç«¯è¿æ¥ã€‚")
            if st.button("ğŸ”„ é‡è¯•åŠ è½½", help="é‡æ–°å°è¯•åŠ è½½æ¨¡å‹åˆ—è¡¨"):
                load_available_models()
                st.rerun()
        
        st.divider()

        # æç¤ºè¯è®¾ç½®éƒ¨åˆ†
        st.subheader("ğŸ’­ æç¤ºè¯è®¾ç½®")
        
        # æç¤ºè¯æ¨¡å¼é€‰æ‹©
        prompt_mode = st.radio(
            "é€‰æ‹©æç¤ºè¯æ¨¡å¼",
            ["é¢„è®¾", "è‡ªå®šä¹‰"],
            key="prompt_mode_radio",
            help="é€‰æ‹©ä½¿ç”¨é¢„è®¾æç¤ºè¯æˆ–è‡ªå®šä¹‰æç¤ºè¯"
        )
        
        # æ›´æ–°session stateä¸­çš„prompt_mode
        if prompt_mode != st.session_state.prompt_mode:
            st.session_state.prompt_mode = prompt_mode
            
        if prompt_mode == "é¢„è®¾":
            # é¢„è®¾æç¤ºè¯é€‰æ‹©
            preset_options = {prompt["name"]: prompt for prompt in PRESET_PROMPTS}
            selected_preset = st.selectbox(
                "é€‰æ‹©é¢„è®¾æç¤ºè¯",
                options=list(preset_options.keys()),
                index=list(preset_options.keys()).index(st.session_state.selected_preset_prompt),
                format_func=lambda x: f"{x} - {preset_options[x]['description']}",
                key="preset_prompt_selector"
            )
            
            # æ›´æ–°é€‰ä¸­çš„é¢„è®¾æç¤ºè¯
            if selected_preset != st.session_state.selected_preset_prompt:
                st.session_state.selected_preset_prompt = selected_preset
                st.session_state.system_prompt = preset_options[selected_preset]["prompt"]
                
            # æ˜¾ç¤ºå½“å‰é¢„è®¾æç¤ºè¯çš„å†…å®¹
            if st.session_state.system_prompt:
                with st.expander("æŸ¥çœ‹å½“å‰æç¤ºè¯"):
                    st.text_area(
                        "å½“å‰ç”Ÿæ•ˆçš„ç³»ç»Ÿæç¤ºè¯",
                        value=st.session_state.system_prompt,
                        disabled=True,
                        height=100
                    )
        else:
            # è‡ªå®šä¹‰æç¤ºè¯è¾“å…¥
            custom_prompt = st.text_area(
                "è¾“å…¥è‡ªå®šä¹‰æç¤ºè¯",
                value=st.session_state.system_prompt,
                height=150,
                help="è¾“å…¥è‡ªå®šä¹‰çš„ç³»ç»Ÿæç¤ºè¯ï¼Œç”¨äºæŒ‡å¯¼AIçš„å›ç­”æ–¹å¼",
                key="custom_prompt_input"
            )
            
            # æ›´æ–°è‡ªå®šä¹‰æç¤ºè¯
            if custom_prompt != st.session_state.system_prompt:
                st.session_state.system_prompt = custom_prompt
        
        # æ¸…ç©ºæç¤ºè¯æŒ‰é’®
        if st.button("ğŸ—‘ æ¸…ç©ºæç¤ºè¯", help="æ¸…é™¤å½“å‰çš„ç³»ç»Ÿæç¤ºè¯"):
            st.session_state.system_prompt = ""
            st.session_state.selected_preset_prompt = "é»˜è®¤åŠ©æ‰‹"
            st.rerun()
            
        # æ·»åŠ æµ‹è¯•æŒ‰é’®
        if st.button("ğŸ§ª æµ‹è¯•æç¤ºè¯", help="æµ‹è¯•å½“å‰æç¤ºè¯æ˜¯å¦ç”Ÿæ•ˆ"):
            with st.spinner("æ­£åœ¨æµ‹è¯•æç¤ºè¯..."):
                test_prompt = "ä½ æ˜¯è°ï¼Ÿè¯·ä»‹ç»ä¸€ä¸‹ä½ è‡ªå·±çš„è§’è‰²ã€‚"
                try:
                    response = requests.post(
                        'http://localhost:8000/api/qa',
                        json={
                            'question': test_prompt,
                            'model_name': st.session_state.current_model,
                            'temperature': st.session_state.temperature,
                            'system_prompt': st.session_state.system_prompt
                        },
                        timeout=30
                    )
                    response.raise_for_status()
                    data = response.json()
                    
                    if data.get('status') == 'success':
                        st.success("æç¤ºè¯æµ‹è¯•æˆåŠŸï¼")
                        st.markdown("**æµ‹è¯•é—®é¢˜ï¼š**\n" + test_prompt)
                        st.markdown("**AIå›ç­”ï¼š**\n" + data.get('response_message', ''))
                    else:
                        st.error(f"æµ‹è¯•å¤±è´¥: {data.get('error', 'æœªçŸ¥é”™è¯¯')}")
                except Exception as e:
                    st.error(f"æµ‹è¯•å‡ºé”™: {str(e)}")

        st.divider()

        st.subheader("çŸ¥è¯†å›¾è°±")
        if st.button("ğŸ“Š æ˜¾ç¤ºçŸ¥è¯†å›¾è°±" if not st.session_state.show_graph else "ğŸ“Š éšè—çŸ¥è¯†å›¾è°±", 
                    help="ç‚¹å‡»æ˜¾ç¤ºæˆ–éšè—çŸ¥è¯†å›¾è°±",
                    key="knowledge_graph_btn"):
            toggle_knowledge_graph()
            st.rerun()  # å¼ºåˆ¶é‡æ–°åŠ è½½é¡µé¢ä»¥åº”ç”¨å¸ƒå±€å˜åŒ–
            
        # æ·»åŠ æµ‹è¯•æŒ‰é’®
        st.divider()
        if st.button("ğŸ§ª æµ‹è¯•ä¸‰å…ƒç»„æå–", help="æµ‹è¯•ä¸‰å…ƒç»„æå–åŠŸèƒ½"):
            st.session_state.show_test = True
            st.rerun()

    # ä¸»èŠå¤©åŒºåŸŸ
    st.markdown("<h3 style='text-align: center;'>GridSeek Chat</h3>", unsafe_allow_html=True)
    
    # æ˜¾ç¤ºå½“å‰æ¨¡å‹ä¿¡æ¯
    col1, col2, col3 = st.columns([1, 2, 1])
    with col2:
        st.markdown(
            f"<div style='text-align: center; padding: 5px; background-color: #f0f2f6; border-radius: 5px; margin-bottom: 10px;'>"
            f"ğŸ¤– å½“å‰æ¨¡å‹: <strong>{st.session_state.current_model}</strong> | "
            f"ğŸŒ¡ï¸ æ¸©åº¦: <strong>{st.session_state.temperature}</strong>"
            f"</div>", 
            unsafe_allow_html=True
        )
        
        # æ˜¾ç¤ºå½“å‰æç¤ºè¯ä¿¡æ¯
        if st.session_state.system_prompt:
            st.markdown(
                f"<div style='text-align: center; padding: 5px; background-color: #e8f4ea; border-radius: 5px; margin-bottom: 10px;'>"
                f"ğŸ’­ å½“å‰æç¤ºè¯: <strong>{st.session_state.selected_preset_prompt if st.session_state.prompt_mode == 'é¢„è®¾' else 'è‡ªå®šä¹‰æç¤ºè¯'}</strong>"
                f"</div>",
                unsafe_allow_html=True
            )
    
    # å¦‚æœéœ€è¦æ˜¾ç¤ºæµ‹è¯•ç•Œé¢
    if st.session_state.get('show_test', False):
        # åˆ›å»ºä¸¤ä¸ªæ ‡ç­¾é¡µ
        tab1, tab2 = st.tabs(["ğŸ§ª ä¸‰å…ƒç»„æå–æµ‹è¯•", "ğŸ¤– æ¨¡å‹åˆ‡æ¢æµ‹è¯•"])
        
        with tab1:
            test_triplet_extraction()
        
        with tab2:
            test_model_switching()
            
        if st.button("è¿”å›èŠå¤©"):
            st.session_state.show_test = False
            st.rerun()
        return

    # æ ¹æ®æ˜¯å¦æ˜¾ç¤ºå›¾è°±å†³å®šå¸ƒå±€
    if st.session_state.show_graph:
        # åˆ›å»ºä¸¤æ å¸ƒå±€
        chat_col, graph_col = st.columns([1, 1])
        
        # å·¦ä¾§æ ï¼šèŠå¤©å†…å®¹
        with chat_col:
            # æ˜¾ç¤ºèŠå¤©å†å²
            for message in st.session_state.messages:
                with st.chat_message(message["role"]):
                    st.markdown(message["content"])
            
            # è·å–ç”¨æˆ·è¾“å…¥
            if prompt := st.chat_input("åœ¨è¿™é‡Œè¾“å…¥æ‚¨çš„é—®é¢˜"):
                # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯
                st.session_state.messages.append({"role": "user", "content": prompt})
                
                # å°†æ¶ˆæ¯åŒæ­¥åˆ°å½“å‰ä¼šè¯
                if st.session_state.current_session:
                    st.session_state.sessions[st.session_state.current_session] = st.session_state.messages.copy()
                
                # æ˜¾ç¤ºç”¨æˆ·æ¶ˆæ¯
                with st.chat_message("user"):
                    st.markdown(prompt)
                
                # æ˜¾ç¤ºAIæ€è€ƒçŠ¶æ€
                with st.chat_message("assistant"):
                    message_placeholder = st.empty()
                    message_placeholder.markdown("ğŸ¤” æ€è€ƒä¸­...")
                    
                    # è°ƒç”¨åç«¯API
                    try:
                        # å‡†å¤‡è¯·æ±‚æ•°æ®
                        request_data = {
                            'question': prompt,
                            'model_name': st.session_state.current_model,
                            'temperature': st.session_state.temperature,
                            'system_prompt': st.session_state.system_prompt
                        }
                        
                        # æ‰“å°è°ƒè¯•ä¿¡æ¯
                        print(f"å‘é€è¯·æ±‚åˆ°åç«¯ï¼Œå‚æ•°ï¼š{request_data}")
                        
                        response = requests.post(
                            'http://localhost:8000/api/qa',
                            json=request_data,
                            timeout=30
                        )
                        response.raise_for_status()
                        
                        # è§£æå“åº”
                        data = response.json()
                        print(f"åç«¯å“åº”æ•°æ®ï¼š{data}")
                        
                        if data.get('status') == 'success':
                            full_response = data.get('response_message', '')
                            message_placeholder.markdown(full_response)
                            
                            # æ·»åŠ AIå›å¤åˆ°æ¶ˆæ¯åˆ—è¡¨
                            st.session_state.messages.append({"role": "assistant", "content": full_response})
                            
                            # åŒæ­¥åˆ°å½“å‰ä¼šè¯
                            if st.session_state.current_session:
                                st.session_state.sessions[st.session_state.current_session] = st.session_state.messages.copy()
                                save_chat_history()
                            
                            # æå–ä¸‰å…ƒç»„å¹¶åœ¨æœ‰æ–°ä¸‰å…ƒç»„æ—¶é‡æ–°åŠ è½½é¡µé¢
                            if extract_and_store_triplets(full_response) and st.session_state.show_graph:
                                st.rerun()
                        else:
                            error_msg = data.get('error', 'æœªçŸ¥é”™è¯¯')
                            message_placeholder.error(f"ğŸ˜” è·å–å›å¤å¤±è´¥: {error_msg}")
                            return
                            
                    except Exception as e:
                        message_placeholder.error(f"ğŸ˜” è·å–å›å¤å¤±è´¥: {e}")
                        print(f"APIè°ƒç”¨å¼‚å¸¸ï¼š{str(e)}")  # æ‰“å°å¼‚å¸¸ä¿¡æ¯
        
        # å³ä¾§æ ï¼šçŸ¥è¯†å›¾è°±
        with graph_col:
            # åˆ›å»ºä¸€ä¸ªå®¹å™¨æ¥åŒ…å«æ‰€æœ‰å†…å®¹
            graph_container = st.container()
            
            # é¦–å…ˆè®¡ç®—å·¦ä¾§æ çš„å¤§è‡´é«˜åº¦
            # å‡è®¾æ¯æ¡æ¶ˆæ¯å¹³å‡é«˜åº¦ä¸º100pxï¼Œè¿™ä¸ªå€¼å¯ä»¥æ ¹æ®å®é™…æƒ…å†µè°ƒæ•´
            message_count = len(st.session_state.messages)
            estimated_height = max(50, min(message_count * 100, 400))  # è‡³å°‘50pxï¼Œæœ€å¤š400px
            
            # åˆ›å»ºä¸€ä¸ªå ä½å®¹å™¨ï¼Œè®©å›¾è°±æ˜¾ç¤ºåœ¨åº•éƒ¨
            # ä½¿ç”¨CSSçš„flexå¸ƒå±€æ¥å®ç°åº•éƒ¨å¯¹é½
            graph_container.markdown(f"""
            <div style="display: flex; flex-direction: column; height: calc(100vh - 100px);">
                <div style="flex-grow: 1; min-height: {estimated_height}px;"></div>
                <div class="graph-column">
                    <h3>çŸ¥è¯†å›¾è°±å¯è§†åŒ–</h3>
                    <div id="knowledge-graph-container" style="height: 600px; border: 1px solid #e0e0e0; border-radius: 8px; overflow: hidden;">
                    </div>
                </div>
            </div>
            """, unsafe_allow_html=True)
            
            # åœ¨HTMLå®¹å™¨å†…æ¸²æŸ“å›¾è°±
            with graph_container:
                # ä½¿ç”¨st.components.htmlå°†å›¾è°±å†…å®¹æ³¨å…¥åˆ°é¢„å®šä¹‰çš„å®¹å™¨ä¸­
                dynamic_html = generate_dynamic_graph_html(st.session_state.get('triplets', []))
                components.html(dynamic_html, height=600, scrolling=True)
    else:
        # æ ‡å‡†å¸ƒå±€ï¼šåªæ˜¾ç¤ºèŠå¤©
        # æ˜¾ç¤ºèŠå¤©å†å²
        for message in st.session_state.messages:
            with st.chat_message(message["role"]):
                st.markdown(message["content"])
        
        # è·å–ç”¨æˆ·è¾“å…¥
        if prompt := st.chat_input("åœ¨è¿™é‡Œè¾“å…¥æ‚¨çš„é—®é¢˜"):
            # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯
            st.session_state.messages.append({"role": "user", "content": prompt})
            
            # å°†æ¶ˆæ¯åŒæ­¥åˆ°å½“å‰ä¼šè¯
            if st.session_state.current_session:
                st.session_state.sessions[st.session_state.current_session] = st.session_state.messages.copy()
            
            # æ˜¾ç¤ºç”¨æˆ·æ¶ˆæ¯
            with st.chat_message("user"):
                st.markdown(prompt)
            
            # æ˜¾ç¤ºAIæ€è€ƒçŠ¶æ€
            with st.chat_message("assistant"):
                message_placeholder = st.empty()
                message_placeholder.markdown("ğŸ¤” æ€è€ƒä¸­...")
                
                # è°ƒç”¨åç«¯API
                try:
                    response = requests.post(
                        'http://localhost:8000/api/qa',
                        json={
                            'question': prompt,
                            'model_name': st.session_state.current_model,
                            'temperature': st.session_state.temperature,
                            'system_prompt': st.session_state.system_prompt
                        },
                        timeout=30
                    )
                    response.raise_for_status()
                    
                    # è§£æå“åº”
                    data = response.json()
                    
                    if data.get('status') == 'success':
                        full_response = data.get('response_message', '')
                        message_placeholder.markdown(full_response)
                    else:
                        error_msg = data.get('error', 'æœªçŸ¥é”™è¯¯')
                        message_placeholder.error(f"ğŸ˜” è·å–å›å¤å¤±è´¥: {error_msg}")
                        return
                    
                    # æ·»åŠ AIå›å¤åˆ°æ¶ˆæ¯åˆ—è¡¨
                    st.session_state.messages.append({"role": "assistant", "content": full_response})
                    
                    # åŒæ­¥åˆ°å½“å‰ä¼šè¯
                    if st.session_state.current_session:
                        st.session_state.sessions[st.session_state.current_session] = st.session_state.messages.copy()
                        save_chat_history()
                    
                    # æå–ä¸‰å…ƒç»„å¹¶åœ¨æœ‰æ–°ä¸‰å…ƒç»„æ—¶é‡æ–°åŠ è½½é¡µé¢
                    if extract_and_store_triplets(full_response) and st.session_state.show_graph:
                        st.rerun()
                    
                except Exception as e:
                    message_placeholder.error(f"ğŸ˜” è·å–å›å¤å¤±è´¥: {e}")

if __name__ == "__main__":
    # åˆå§‹åŒ–æµ‹è¯•æ ‡å¿—
    if 'show_test' not in st.session_state:
        st.session_state.show_test = False
    main()

# é¡µé¢åº•éƒ¨
st.markdown("---")
st.caption("Â© 2024 Gridseek | Powered by Streamlit")